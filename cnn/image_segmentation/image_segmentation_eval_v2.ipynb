{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Segmentation for Evaluation\n",
    "\n",
    "* MeanIOU: Image Segmentation에서 많이 쓰이는 evaluation measure\n",
    "* tf.version 1.12 API: [`tf.metrics.mean_iou`](https://www.tensorflow.org/api_docs/python/tf/metrics/mean_iou)\n",
    "  * `tf.enable_eager_execution()`이 작동하지 않음\n",
    "  * 따라서 예전 방식대로 `tf.Session()`을 이용하여 작성하거나 아래와 같이 2.0 version으로 작성하여야 함\n",
    "* tf.version 2.0 API: [`tf.keras.metrics.MeanIoU`](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/metrics/MeanIoU)\n",
    "* 지금 이 코드는 `version 2` 코드를 이용하여 작성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "import functools\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['axes.grid'] = False\n",
    "mpl.rcParams['figure.figsize'] = (12,12)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.python.keras import layers\n",
    "from tensorflow.python.keras import losses\n",
    "from tensorflow.python.keras import models\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 수집 및 Visualize\n",
    "\n",
    "### Download data [트레이닝 시 이미 받음]\n",
    "\n",
    "이 프로젝트는 [Giana Dataset](https://giana.grand-challenge.org/Dates/)을 이용하여 진행한다.\n",
    "\n",
    "### Split dataset into train data and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH='../../datasets/sd_train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = os.path.join(DATASET_PATH, 'sd_train')\n",
    "\n",
    "img_dir = os.path.join(dataset_dir, \"train\")\n",
    "label_dir = os.path.join(dataset_dir, \"train_labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_filenames = [os.path.join(img_dir, filename) for filename in os.listdir(img_dir)]\n",
    "x_train_filenames.sort()\n",
    "y_train_filenames = [os.path.join(label_dir, filename) for filename in os.listdir(label_dir)]\n",
    "y_train_filenames.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_filenames, x_test_filenames, y_train_filenames, y_test_filenames = \\\n",
    "                    train_test_split(x_train_filenames, y_train_filenames, test_size=0.2, random_state=219)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_examples = len(x_train_filenames)\n",
    "num_test_examples = len(x_test_filenames)\n",
    "\n",
    "print(\"Number of training examples: {}\".format(num_train_examples))\n",
    "print(\"Number of test examples: {}\".format(num_test_examples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build our input pipeline with `tf.data`\n",
    "### Set up test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyperparameters\n",
    "image_size = 256\n",
    "img_shape = (image_size, image_size, 3)\n",
    "batch_size = 60\n",
    "\n",
    "checkpoint_dir = train_dir = 'train/exp1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _process_pathnames(fname, label_path):\n",
    "  # We map this function onto each pathname pair\n",
    "  img_str = tf.io.read_file(fname)\n",
    "  img = tf.image.decode_bmp(img_str, channels=3)\n",
    "\n",
    "  label_img_str = tf.io.read_file(label_path)\n",
    "  label_img = tf.image.decode_bmp(label_img_str, channels=1)\n",
    "  \n",
    "  resize = [image_size, image_size]\n",
    "  img = tf.image.resize(img, resize)\n",
    "  label_img = tf.image.resize(label_img, resize)\n",
    "  \n",
    "  scale = 1 / 255.\n",
    "  img = tf.dtypes.cast(img, tf.float32) * scale\n",
    "  label_img = tf.dtypes.cast(label_img, tf.float32) * scale\n",
    "  \n",
    "  return img, label_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_baseline_dataset(filenames,\n",
    "                         labels,\n",
    "                         threads=5,\n",
    "                         batch_size=batch_size,\n",
    "                         shuffle=True):\n",
    "  num_x = len(filenames)\n",
    "  # Create a dataset from the filenames and labels\n",
    "  dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n",
    "  # Map our preprocessing function to every element in our dataset, taking\n",
    "  # advantage of multithreading\n",
    "  dataset = dataset.map(_process_pathnames, num_parallel_calls=threads)\n",
    "  \n",
    "  if shuffle:\n",
    "    dataset = dataset.shuffle(num_x * 10)\n",
    "  \n",
    "  dataset = dataset.batch(batch_size)\n",
    "  return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = get_baseline_dataset(x_test_filenames,\n",
    "                                    y_test_filenames,\n",
    "                                    shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv(tf.keras.Model):\n",
    "  def __init__(self, num_filters, kernel_size):\n",
    "    super(Conv, self).__init__()\n",
    "    self.conv = layers.Conv2D(num_filters, kernel_size, padding='same')\n",
    "    self.bn = layers.BatchNormalization()\n",
    "\n",
    "  def call(self, inputs, training=True):\n",
    "    x = self.conv(inputs)\n",
    "    x = self.bn(x, training=training)\n",
    "    x = tf.nn.relu(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(tf.keras.Model):\n",
    "  def __init__(self, num_filters):\n",
    "    super(ConvBlock, self).__init__()\n",
    "    self.conv1 = Conv(num_filters, 3)\n",
    "    self.conv2 = Conv(num_filters, 3)\n",
    "\n",
    "  def call(self, inputs, training=True):\n",
    "    encoder = self.conv1(inputs, training=training)\n",
    "    encoder = self.conv2(encoder, training=training)\n",
    "\n",
    "    return encoder\n",
    "\n",
    "\n",
    "class EncoderBlock(tf.keras.Model):\n",
    "  def __init__(self, num_filters):\n",
    "    super(EncoderBlock, self).__init__()\n",
    "    self.conv_block = ConvBlock(num_filters)\n",
    "    self.encoder_pool = layers.MaxPooling2D((2, 2), strides=(2, 2))\n",
    "\n",
    "  def call(self, inputs, training=True):\n",
    "    encoder = self.conv_block(inputs, training=training)\n",
    "    encoder_pool = self.encoder_pool(encoder)\n",
    "\n",
    "    return encoder_pool, encoder\n",
    "\n",
    "\n",
    "class DecoderBlock(tf.keras.Model):\n",
    "  def __init__(self, num_filters):\n",
    "    super(DecoderBlock, self).__init__()\n",
    "    self.convT = layers.Conv2DTranspose(num_filters, 2, strides=2, padding='same')\n",
    "    self.bn = layers.BatchNormalization()\n",
    "    self.conv_block = ConvBlock(num_filters)\n",
    "\n",
    "  def call(self, input_tensor, concat_tensor, training=True):\n",
    "    decoder = self.convT(input_tensor)\n",
    "    decoder = tf.concat([decoder, concat_tensor], axis=-1)\n",
    "    decoder = self.bn(decoder, training=training)\n",
    "    decoder = tf.nn.relu(decoder)\n",
    "    decoder = self.conv_block(decoder, training=training)\n",
    "\n",
    "    return decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(tf.keras.Model):\n",
    "  def __init__(self):\n",
    "    super(UNet, self).__init__()\n",
    "    self.encoder_block1 = EncoderBlock(32)\n",
    "    self.encoder_block2 = EncoderBlock(64)\n",
    "    self.encoder_block3 = EncoderBlock(128)\n",
    "    self.encoder_block4 = EncoderBlock(256)\n",
    "\n",
    "    self.center = ConvBlock(512)\n",
    "\n",
    "    self.decoder_block4 = DecoderBlock(256)\n",
    "    self.decoder_block3 = DecoderBlock(128)\n",
    "    self.decoder_block2 = DecoderBlock(64)\n",
    "    self.decoder_block1 = DecoderBlock(32)\n",
    "\n",
    "    self.output_conv = layers.Conv2D(1, 1, activation='sigmoid')\n",
    "\n",
    "  def call(self, inputs, training=True):\n",
    "    encoder1_pool, encoder1 = self.encoder_block1(inputs)\n",
    "    encoder2_pool, encoder2 = self.encoder_block2(encoder1_pool)\n",
    "    encoder3_pool, encoder3 = self.encoder_block3(encoder2_pool)\n",
    "    encoder4_pool, encoder4 = self.encoder_block4(encoder3_pool)\n",
    "\n",
    "    center = self.center(encoder4_pool)\n",
    "\n",
    "    decoder4 = self.decoder_block4(center, encoder4)\n",
    "    decoder3 = self.decoder_block3(decoder4, encoder3)\n",
    "    decoder2 = self.decoder_block2(decoder3, encoder2)\n",
    "    decoder1 = self.decoder_block1(decoder2, encoder1)\n",
    "\n",
    "    outputs = self.output_conv(decoder1)\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restore using Checkpoints (Object-based saving)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(model=model)\n",
    "\n",
    "# restoring the latest checkpoint in checkpoint_dir\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display prediction mask image for one test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_images, test_labels in test_dataset.take(1):\n",
    "  predictions = model(test_images)\n",
    "        \n",
    "  plt.figure(figsize=(10, 20))\n",
    "  plt.subplot(1, 3, 1)\n",
    "  plt.imshow(test_images[0,: , :, :])\n",
    "  plt.title(\"Input image\")\n",
    "\n",
    "  plt.subplot(1, 3, 2)\n",
    "  plt.imshow(test_labels[0, :, :, 0])\n",
    "  plt.title(\"Actual Mask\")\n",
    "\n",
    "  plt.subplot(1, 3, 3)\n",
    "  plt.imshow(predictions[0, :, :, 0])\n",
    "  plt.title(\"Predicted Mask\")\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the test dataset and Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = tf.keras.metrics.MeanIoU(num_classes=2)\n",
    "\n",
    "for images, labels in test_dataset:\n",
    "  predictions = model(images)\n",
    "  m.update_state( tf.dtypes.cast(tf.math.round(labels), tf.int32),\n",
    "                  tf.dtypes.cast(tf.math.round(predictions), tf.int32) )\n",
    "\n",
    "print('Final Mean IOU result: ', m.result().numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
